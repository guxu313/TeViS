MODEL: 
    clip_path: '/blob_mount/project/script_translator/pretrained/ViT-B-32.pt'
    input_size: 512
    emb_size: 512
    dim_feedforward: 2048
    nhead: 8
    drop_prob: 0.1
    num_encoder_layers: 2

QUANTIZE:
    embed_n             : 4096
    embed_dim_reduce    : 32
    beta                : 0.8

n_layer: 3
model_type: 'prefix' 
mlm_probability: 0.15
eval_clip: true
prompt_frame_num: 0
log_tb: true
quantize: true

is_test: true


WEIGHTS: 
    model_weight: '/blob_mount_save/tevis/saved_model/step_00800/pytorch_model.bin'

DATA:
    BATCH_SIZE_per_gpu: 16     

    NUM_WORKERS: 4
    PIN_MEMORY: True

    input_res: [224, 224]
    sample_frame: 6

    DATASET_train: [{
            'name': 'TeViS',
            'split': 'train',
            'type': 'VideoDataset',
            'metadata_dir':  '/scripts-translator/metadata/MovieNet_TeViS/train.json',
            'video_path': '/blob_mount/datasets/240P',
            'sample_rate': 1,
            'max_length': 12,
        },
        ]

    DATASET_val: [{
            'name': 'TeViS',
            'split': 'val',
            'type': 'VideoDataset',
            'metadata_dir': '/scripts-translator/metadata/MovieNet_TeViS/test.json',
            'video_path': '/blob_mount/datasets/240P',
            'sample_rate': 1,
            'max_length': 12,
        },
        ]


TRAINING:
    BREAK_STEP: 10000000000
    EPOCHS: 1000
    WARMUP_EPOCHS: 1
    WARMUP_LR: 0.
    LR_SCHEDULER: {
        'NAME': 'linear',
        'DECAY_EPOCHS': 2,
        }


    temp: 0.01
    weight_decay: 0.2

    save_dir: "/blob_mount_save/tevis_test/"
    checkpoint_step: 4000
    save_step: 200
    print_step: 10
    eval_step: 200

deepspeed_config: {
    "train_micro_batch_size_per_gpu": 16, 
    "gradient_accumulation_steps": 1,
    "steps_per_print": 500,


    "zero_optimization": {
      "stage": 2,
      "allgather_partitions": true,
      "allgather_bucket_size": 5.0e+8,
      "overlap_comm": false,
      "reduce_scatter": true,
      "reduce_bucket_size": 5.0e+8,
      "contiguous_gradients" : false,
      "stage3_gather_fp16_weights_on_model_save": true
    },

    "fp16": {
      "enabled": false,
      "loss_scale": 0,
      "loss_scale_window": 1000,
      "initial_scale_power": 32,
      "hysteresis": 2,
      "min_loss_scale": 1
  },

    "optimizer": {
        "type": "AdamW",
        "params": {
        "lr": 1.0e-6,
        "betas": [0.9, 0.98],
        "eps": 1.0e-8,
        "weight_decay": 5.0e-2
        }
    },


    "sparse_attention": {
      "mode": "fixed",
      "block": 32,
      "different_layout_per_head": true,
      "num_local_blocks": 16,
      "num_global_blocks": 1,
      "attention": "bidirectional",
      "horizontal_global_attention": true,
      "num_different_global_patterns": 4
    }
}


  


  
